# mcp-webcrawler 项目扩展规划 TODO List

## 📋 项目概述

MCP Server（Model Context Protocol Server）用于网页或站点爬取与上下文数据提供。
让大模型能够以统一的接口访问任意 Web 页面或站点，自动抓取网页内容、结构化数据，并以统一格式返回。

---

## 🧱 阶段 1：核心功能 MVP

### 主要功能
- [x] 支持 `crawl_page(url)` 抓取单页面
- [x] 自动提取 `<title>`、正文文本、meta 信息
- [x] 结果结构化输出到 JSON
- [x] MCP Server 提供 `crawl_page` 工具
- [x] 实现限速与站点白名单支持

### 技术实现
- [x] HTTP/HTTPS 请求处理
- [x] HTML 解析与 DOM 导航
- [x] 内容提取引擎
- [x] 链接和图片提取
- [x] 元数据获取
- [x] 错误处理和超时控制

### 测试与部署
- [x] 单元测试（覆盖率 ≥70%）
- [x] 集成测试
- [x] 代码格式化与静态分析
- [x] 二进制构建与发布

**输出目标**：第一个可用的 MCP 插件，能让 Claude / ChatGPT 通过 MCP 访问网页。

---

## ⚙️ 阶段 2：增强功能与性能优化

### 内容处理增强
- [ ] 实现整站递归爬取（带深度控制）
- [x] 引入内容清洗器（去广告、正文提取）
- [ ] 增加内容摘要生成（LLM 辅助摘要）

### 缓存与性能
- [ ] SQLite 缓存存储实现
- [ ] 缓存与增量更新策略（etag、last-modified）
- [ ] Redis 缓存集成（可选）
- [ ] 并发控制与性能优化
- [ ] 请求速率限制

- [ ] `crawl_site(url, depth)` 整站爬取接口
- [ ] `get_content(id)` 查询缓存内容接口
- [ ] `clear_cache()` 清空缓存接口

---

## 🧠 阶段 3：智能化与多源融合

### 多源数据支持
- [ ] RSS feed 解析与更新
- [ ] API 数据源接入
- [ ] Sitemap.xml 自动发现
- [ ] JSON 数据格式支持

### 智能功能
- [ ] 智能站点结构识别
- [ ] 自动爬取策略生成
- [ ] 内容去重与合并
- [ ] 自动更新周期检测

### 搜索与检索
- [ ] ElasticSearch 集成
- [ ] 全文检索 API
- [ ] 高级查询语法支持
- [ ] 搜索结果排序优化

### 安全与授权
- [ ] Token 认证支持
- [ ] JWT 认证实现
- [ ] OAuth2 集成
- [ ] 基于角色的访问控制（RBAC）

## 🌍 阶段 4：企业级 & 知识库接入

### 向量化与嵌入
- [ ] 网页内容向量化处理
- [ ] Embedding 生成接口
- [ ] 向量存储优化
- [ ] 相似度搜索功能

### 向量数据库集成
- [ ] Milvus 集成
- [ ] Weaviate 集成
- [ ] Qdrant 集成
- [ ] 多向量库支持

### LLM Agent 集成
- [ ] LangChain 插件接口
- [ ] Claude MCP 协议完全兼容
- [ ] Agent 工具链集成
- [ ] 上下文管理优化

### 统一知识平台
- [ ] 多源内容统一索引
- [ ] 混合搜索（Web + API + 文件）
- [ ] 知识图谱构建
- [ ] 内容关系分析

### 企业部署
- [ ] Docker 镜像构建
- [ ] Kubernetes 部署配置
- [ ] Helm Chart 发布
- [ ] 多节点集群支持
- [ ] 监控与日志系统

---

## 💡 长远规划：智能知识采集中枢

### 核心目标
- [ ] 自动发现、抓取、更新、清洗全网内容
- [ ] 为 LLM 提供实时上下文
- [ ] 支持企业内外网融合（公网 + 私有文档）
- [ ] 成为知识驱动 AI 应用的基础设施组件

### 高级功能
- [ ] 内容质量评分
- [ ] 信息溯源与验证
- [ ] 多语言支持
- [ ] 跨域知识融合
- [ ] 自适应爬虫策略

---

## 🔧 模块功能清单

### Crawler 模块
- [x] 单页面爬取
- [x] HTTP/HTTPS 支持
- [ ] robots.txt 遵循
- [ ] 并发控制
- [ ] 递归爬取
- [ ] 深度限制

### Parser 模块
- [x] HTML 解析
- [ ] JSON 解析
- [ ] RSS 解析
- [ ] Markdown 解析
- [ ] 表格提取
- [x] 图片信息提取

### Content Cleaner
- [ ] 去除广告
- [ ] 导航清理
- [ ] 重复内容去重
- [ ] 追踪参数移除
- [x] 正文提取
- [ ] 噪音过滤

### Storage 模块
- [ ] SQLite 支持
- [ ] PostgreSQL 支持
- [ ] ElasticSearch 支持
- [ ] 缓存管理
- [ ] 备份恢复
- [ ] 数据迁移工具

### API 层 (MCP)
- [x] `crawl_page(url)` 接口
- [ ] `crawl_site(url, depth)` 接口
- [ ] `get_content(id)` 接口
- [ ] `search(query)` 接口
- [ ] `list_urls()` 接口
- [ ] `get_metadata()` 接口

### 安全与策略控制
- [ ] 域名白名单
- [ ] IP 限制
- [ ] 爬取速率限制
- [ ] 请求超时控制
- [x] User-Agent 管理
- [ ] 代理轮转支持

### LLM Adapter
- [x] JSON 格式化输出
- [ ] Markdown 格式输出
- [ ] 自定义格式模板
- [ ] 多语言支持
- [ ] 内容摘要生成
- [ ] 关键词提取

---

## 📊 数据格式定义

### 爬取结果格式
```json
{
  "url": "https://example.com/article/123",
  "title": "Example Article Title",
  "description": "Article meta description",
  "content": "This is the main body text of the article...",
  "author": "John Doe",
  "published_at": "2025-10-20T12:00:00Z",
  "updated_at": "2025-10-21T14:30:00Z",
  "content_type": "text/html",
  "links": [
    {"href": "https://example.com/about", "text": "About Us"},
    {"href": "https://example.com/contact", "text": "Contact"}
  ],
  "images": [
    {"src": "https://example.com/img.jpg", "alt": "Example Image"}
  ],
  "tags": ["technology", "web"],
  "language": "en",
  "metadata": {
    "status_code": 200,
    "fetch_time_ms": 1234,
    "source": "example.com",
    "hash": "abc123def456"
  }
}
```

---

## 📈 技术栈选型

### 核心框架
- [x] Go 1.21+ (已选择)
- [ ] Rust (可选替代)
- [ ] Python (可选替代)

### 关键依赖（已集成）
- [x] github.com/modelcontextprotocol/go-sdk v1.0.0
- [x] github.com/PuerkitoBio/goquery v1.10.3
- [x] github.com/google/jsonschema-go v0.3.0

### 待集成依赖
- [ ] github.com/go-rod/rod (JavaScript 渲染)
- [ ] gorm.io/gorm (ORM)
- [ ] elasticsearch/go-elasticsearch (搜索)
- [ ] redis/go-redis (缓存)

---

## 🎯 质量目标

### 代码标准
- [x] 所有代码使用中文注释
- [x] 函数命名规范 (PascalCase/camelCase)
- [x] 代码格式化 (go fmt)
- [x] 静态分析通过 (go vet)

### 测试覆盖
- [x] 单元测试覆盖率 ≥70% (核心包)
- [ ] 集成测试完整
- [ ] 性能基准测试
- [ ] 压力测试

### 文档
- [x] README.md 项目说明
- [x] AGENTS.md 开发指南
- [ ] API 文档完整
- [ ] 架构设计文档
- [ ] 部署指南

---

## 🚀 里程碑

- [x] **v0.1.0** - MVP 发布 (单页面爬取)
- [ ] **v0.2.0** - 增强功能 (整站爬取、缓存、清洗)
- [ ] **v0.3.0** - 智能化 (多源、搜索、授权)
- [ ] **v1.0.0** - 企业级 (向量、Agent、部署)
- [ ] **v2.0.0** - 知识中枢 (完整平台)

---

## 📝 注记

- 按优先级完成任务
- 每个阶段完成后更新此文档
- 定期评估技术选型
- 保持与社区最佳实践同步

---

## 📄 从 README.md 中提取的未完成项目

根据 README.md 的设计和描述，以下功能仍需实现或完善：

### 功能实现部分

#### 1. 站点爬取功能（README Section 2: 站点爬取 - 可选）
- [ ] 实现递归爬取整个网站功能
- [ ] 添加深度限制参数 `max_depth` 支持
- [ ] 添加页面数量限制 `limit_pages` 参数
- [ ] 添加域名限制 `same_domain_only` 参数
- [ ] 支持原始 HTML 输出格式
- [ ] 支持纯文本提取输出格式
- [ ] 支持链接结构（网站图谱）输出模式
- [ ] 实现站点爬取的性能优化
- [ ] 为 `crawl_site` 工具添加完整 MCP 接口定义

#### 2. 任务异步执行功能（README Section 1.5: 任务异步执行 - 可选）
- [ ] 设计异步任务队列系统
- [ ] 实现任务 ID 生成和管理机制
- [ ] 为大型站点添加异步后台处理能力
- [ ] 实现 `GET /tasks/{id}` 轮询接口
- [ ] 实现任务状态追踪（pending, running, completed, failed）
- [ ] 添加任务超时处理机制
- [ ] 实现任务队列的持久化存储
- [ ] 添加任务结果缓存功能
- [ ] 实现任务进度报告接口

#### 3. 模型友好输出功能（README Section 1.4: 模型友好输出）
- [ ] 实现完整的 Markdown 格式输出支持
- [ ] 实现内容自动分块（chunking）功能
  - [ ] 基于段落的分块策略
  - [ ] 基于 token 数量的分块策略
  - [ ] 重叠窗口支持
- [ ] 添加摘要生成模式（使用 LLM 或文本摘要算法）
- [ ] 实现片段化返回选项（按需返回部分内容）
- [ ] 为向量 embedding 优化输出格式
- [ ] 实现语义索引格式化
- [ ] 支持自定义输出模板
- [ ] 添加多语言输出支持

#### 4. 内容结构化增强（README Section 1.3: 内容结构化）
- [ ] 完善图片 URL 和 alt 文本提取
  - [ ] 处理相对 URL 转绝对 URL
  - [ ] 支持 srcset 属性解析
  - [ ] 支持 WebP 和其他现代格式检测
- [ ] 实现视频链接提取
  - [ ] 支持 HTML5 <video> 标签
  - [ ] 支持 iframe 嵌入视频
  - [ ] 支持视频平台链接识别
- [ ] 添加完整的媒体元数据收集
  - [ ] 图片尺寸信息
  - [ ] 视频时长
  - [ ] 媒体类型识别
- [ ] 实现媒体优先级排序
- [ ] 添加音频内容提取

### 安全与治理部分

#### 5. 安全增强功能（README Section 5: 安全与治理）
- [ ] 实现完整的域名白名单机制
  - [ ] 配置文件支持
  - [ ] 动态白名单管理接口
  - [ ] 正则表达式匹配支持
- [ ] 完善内网 IP 黑名单检查
  - [ ] 检查 127.0.0.1 范围
  - [ ] 检查 10.0.0.0/8 范围
  - [ ] 检查 172.16.0.0/12 范围
  - [ ] 检查 192.168.0.0/16 范围
  - [ ] 检查本地链接地址 (169.254.0.0/16)
  - [ ] IPv6 本地地址检查
- [ ] 添加 file:// URL 协议禁用
- [ ] 添加 localhost 和 127.0.0.1 访问禁用
- [ ] 实现全局请求限速机制
  - [ ] 每秒请求数限制
  - [ ] 每个 IP 的限制
  - [ ] 每个域名的限制
- [ ] 添加请求间延迟策略
- [ ] 实现 User-Agent 随机化
- [ ] 实现缓存去重策略
- [ ] 添加敏感内容脱敏功能
  - [ ] 密钥脱敏
  - [ ] 邮箱脱敏
  - [ ] 电话号码脱敏
- [ ] 完善审计日志记录
  - [ ] 请求来源记录
  - [ ] 访问目标记录
  - [ ] 访问结果记录
  - [ ] 错误详情记录

### 使用场景验证

#### 6. 场景集成测试（README Section 2: 使用场景）
- [ ] 验证信息抽取场景
  - [ ] 新闻文章数据抽取
  - [ ] 产品信息数据抽取
  - [ ] 价格数据抽取
- [ ] 测试内容理解工作流
  - [ ] 问答场景
  - [ ] 内容总结场景
  - [ ] 事实检验场景
- [ ] 验证语义索引 RAG 集成
  - [ ] 向量化处理
  - [ ] 向量存储集成
  - [ ] 检索增强生成测试
- [ ] 测试实时信息更新流程
  - [ ] 增量更新检测
  - [ ] 变化通知机制
  - [ ] 缓存失效策略
- [ ] 验证内容监控功能
  - [ ] 页面变化检测
  - [ ] 死链检测
  - [ ] 内容过期检测

### 示例与文档

#### 7. 最小化实现示例（README 文档末尾的问题）
- [ ] 创建可直接运行的 Go MCP Server 完整示例
- [ ] 编写支持 `crawl_page` 工具的完整代码示例
- [ ] 编写支持 `crawl_site` 工具的完整代码示例
- [ ] 提供与 Claude/ChatGPT 集成的实战指南
- [ ] 添加环境配置示例文件（.env.example）
- [ ] 提供使用说明和常见问题解答
- [ ] 创建 Rust 版本的参考实现（如需）
- [ ] 创建 Python 版本的参考实现（如需）

#### 8. 技术选型文档完善
- [ ] 补充所有技术方案的详细选型说明
- [ ] 比较 Go、Rust、Python 实现的优缺点
  - [ ] 性能对比分析
  - [ ] 开发效率对比
  - [ ] 依赖生态对比
  - [ ] 部署复杂度对比
- [ ] 记录各模块的具体技术栈决策理由
  - [ ] Web 抓取模块选型理由
  - [ ] HTML 解析模块选型理由
  - [ ] 缓存方案选型理由
  - [ ] 并发处理方案理由
- [ ] 添加依赖库选择的详细理由说明
- [ ] 记录技术选型的权衡考虑

#### 9. API 文档完善
- [ ] 补充 `crawl_page` 工具的详细 API 文档
  - [ ] 所有参数说明
  - [ ] 返回值格式说明
  - [ ] 错误码定义
  - [ ] 使用示例
- [ ] 补充 `crawl_site` 工具的详细 API 文档
  - [ ] 所有参数说明
  - [ ] 返回值格式说明
  - [ ] 错误码定义
  - [ ] 使用示例
- [ ] 编写架构设计文档
- [ ] 编写部署运维指南
- [ ] 编写故障排除指南

### 系统设计补完

#### 10. 架构设计完善（README Section 3: 系统设计）
- [ ] 详细设计调度器/工作者组件
- [ ] 设计缓存管理策略
- [ ] 设计并发控制机制
- [ ] 设计错误处理和恢复策略
- [ ] 设计监控和告警机制
- [ ] 设计可扩展性架构
  - [ ] 水平扩展支持
  - [ ] 负载均衡
  - [ ] 状态共享

---

## 📋 总结

README.md 中的以下部分标记为"可选"或"待实现"：
1. **Section 2: 站点爬取** - 可选功能，需要完整实现
2. **Section 1.4 & 1.5** - 模型友好输出和异步任务执行
3. **Section 5** - 安全与治理的多个细节需要完善
4. **文档末尾** - 提出了创建 Rust/Python 版本的问题

这些项目已按逻辑顺序和优先级列在本部分，供项目后续开发参考。
